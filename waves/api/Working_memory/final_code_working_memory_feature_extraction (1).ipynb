{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "499acec4",
   "metadata": {},
   "source": [
    "# lmports and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c514bda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable       delta_coherence_calculation \n",
    "# Class          Captial\n",
    "# function       butterBandpassFilter\n",
    "# meegkiit install -- command window\n",
    "# variable names -- solved - next meeting\n",
    "# definition of function -- solved - next meeting\n",
    "# Visualization interpretation -- future\n",
    "# welch - methods extraction -- future \n",
    "# Introduction to asymetry, coherence , ... by Pegah\n",
    "\n",
    "# parameter      delta_coherence_calculation\n",
    "# variable       var_delta_coherence_calculation \n",
    "# Class          Captial\n",
    "# function       butterBandpassFilter\n",
    "# internal variables or parameter name with _ at the beginning eg: _counter\n",
    "import mne\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import scipy.signal as ss\n",
    "import pyedflib\n",
    "from scipy.signal import hilbert,butter, lfilter,welch\n",
    "from scipy.integrate import simps\n",
    "from meegkit.asr import ASR\n",
    "from meegkit.utils.matrix import sliding_window\n",
    "from mne.time_frequency import psd_array_multitaper\n",
    "from neurodsp.utils.download import load_ndsp_data\n",
    "sampling_rate = 1000\n",
    "#frequency rythms\n",
    "#Delta:0.5-4\n",
    "#Theta:4-8\n",
    "#Alpha: 8-13\n",
    "#Beta: 13-30\n",
    "#Gamma:30-45\n",
    "#eeg channels corresponding brain area\n",
    "# left frontal (Fl)=fp1,f3,f7=0,2,10\n",
    "# right frontal (Fr)=fp2,f4,f8=1,3,11\n",
    "# left central (C)=t3, c3=12,4\n",
    "# right central (C)=t4, c4=13,5\n",
    "# left parietal-occipital (lPO)=t5,p3,o1=14,6,8\n",
    "# right parietal-occipital (rPO)=t6,p4,o2=15,7,9\n",
    "# midline (M)=fz,cz,pz=17,16,18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3180f1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def butterBandpass(data, lower_limit_filter, upper_limit_filter, sampling_rate, order=4):\n",
    "    \"\"\"\n",
    "    This func is for filtering signal between lower and upper bounds\n",
    "    the methods are used from scipy.signal lib\n",
    "    \"\"\"\n",
    "    nyquist_coeff = 0.5 * sampling_rate\n",
    "    low_frequences_filter = lower_limit_filter / nyquist_coeff\n",
    "    high_frequences_filter = upper_limit_filter / nyquist_coeff\n",
    "    numerator_filter, denominator_filter = butter(order, \n",
    "                                                  [low_frequences_filter, high_frequences_filter],\n",
    "                                                  btype='band')\n",
    "    # based on numinator and denominator the filter signal ...                                            )\n",
    "    filtered_signal = lfilter(numerator_filter, denominator_filter, data)\n",
    "    return filtered_signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fec383c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyArtifactSubspaceReconstruction(raw, sfreq=sampling_rate, cutoff=2.5, \n",
    "                                        blocksize=100, win_len=0.5,\n",
    "                                        win_overlap=0.66, max_dropout_fraction=0.1,\n",
    "                                        min_clean_fraction=0.25, name='asrfilter', method='euclid',\n",
    "                                        estimator='scm'):\n",
    "    \"\"\"\n",
    "    Goal: this function removes artifact specially those related to EOG noises\n",
    "    \"\"\"\n",
    "    h, w = raw.shape\n",
    "    \n",
    "    # t = int(raw.shape[1] / sfreq)\n",
    "    # take asr ....\n",
    "    asr = ASR(sfreq=sfreq, cutoff=cutoff, blocksize=blocksize, win_len=win_len,\n",
    "        win_overlap=win_overlap, max_dropout_fraction=max_dropout_fraction,\n",
    "        min_clean_fraction=min_clean_fraction, name=name, method=method,\n",
    "        estimator=estimator)\n",
    "        \n",
    "    # method='euclid'\n",
    "    # train_idx = np.arange(0 * sfreq, t * sfreq, dtype=int)\n",
    "    \n",
    "    # short description ....\n",
    "    _, sample_mask = asr.fit(raw)\n",
    "    \n",
    "    # Apply filter using sliding (non-overlapping) windows\n",
    "    # name X, Y\n",
    "    # description\n",
    "    \n",
    "    #sliding_window function converts our 2-D data(number of channels by number of recorded samples) dataset to a 3-D function(number of channels by time in second by sampling rate) \n",
    "    X = sliding_window(raw, window=int(sfreq), step=int(sfreq))\n",
    "    \n",
    "    Y = np.zeros_like(X)\n",
    "    for i in range(X.shape[1]):\n",
    "        Y[:, i, :] = asr.transform(X[:, i, :])\n",
    "    \n",
    "   # reshape to (n_chans, n_times)\n",
    "    clean = Y.reshape(h, -1)\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9c48f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bandPower(data, sampling_rate, frequency_band, method='welch', window_sec=None, relative=False):\n",
    "    frequency_band = np.asarray(frequency_band)\n",
    "    low_limitation, high_limitation = frequency_band\n",
    "    # Compute the modified periodogram (Welch)\n",
    "    if method == 'welch':\n",
    "        if window_sec is not None:\n",
    "            num_of_sample_per_segment = window_sec * sampling_rate\n",
    "        else:\n",
    "            num_of_sample_per_segment = (2 / low_limitation) * sampling_rate\n",
    "        freqs, psd = welch(data, sampling_rate, nperseg=num_of_sample_per_segment)\n",
    "    elif method == 'multitaper':\n",
    "        psd, freqs = psd_array_multitaper(data, sampling_rate, adaptive=True,\n",
    "                                          normalization='full', verbose=0)\n",
    "    # Frequency resolution\n",
    "    freq_res = freqs[1] - freqs[0]\n",
    "\n",
    "    # Find index of band in frequency vector\n",
    "    idx_band = np.logical_and(freqs >= low_limitation, freqs <= high_limitation)\n",
    "\n",
    "    # Integral approximation of the spectrum using parabola (Simpson's rule)\n",
    "    bp = simps(psd[idx_band], dx=freq_res)\n",
    "\n",
    "    if relative:\n",
    "        bp /= simps(psd, dx=freq_res)\n",
    "    return bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38b4e13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def myBandPower(data, sampling_rate, \n",
    "                frequency_band1,frequency_band2,frequency_band3,frequency_band4,frequency_band5,frequency_band6,\n",
    "                frequency_band7,frequency_band8,frequency_band9,frequency_band10,\n",
    "                method='welch', window_sec=None):\n",
    "    frequency_band1 = np.asarray(frequency_band1)\n",
    "    frequency_band2 = np.asarray(frequency_band2)\n",
    "    frequency_band3 = np.asarray(frequency_band3)\n",
    "    frequency_band4 = np.asarray(frequency_band4)\n",
    "    frequency_band5 = np.asarray(frequency_band5)\n",
    "    frequency_band6 = np.asarray(frequency_band6)\n",
    "    frequency_band7 = np.asarray(frequency_band7)\n",
    "    frequency_band8 = np.asarray(frequency_band8)\n",
    "    frequency_band9 = np.asarray(frequency_band9)\n",
    "    frequency_band10 = np.asarray(frequency_band10)\n",
    "    \n",
    "    low_limitation1, high_limitation1 = frequency_band1\n",
    "    low_limitation2, high_limitation2 = frequency_band2\n",
    "    low_limitation3, high_limitation3 = frequency_band3\n",
    "    low_limitation4, high_limitation4 = frequency_band4\n",
    "    low_limitation5, high_limitation5 = frequency_band5\n",
    "    low_limitation6, high_limitation6 = frequency_band6\n",
    "    low_limitation7, high_limitation7 = frequency_band7\n",
    "    low_limitation8, high_limitation8 = frequency_band8\n",
    "    low_limitation9, high_limitation9 = frequency_band9\n",
    "    low_limitation10, high_limitation10 = frequency_band10\n",
    "    # Compute the modified periodogram (Welch)\n",
    "    if method == 'welch':\n",
    "        if window_sec is not None:\n",
    "            num_of_sample_per_segment = window_sec * sampling_rate\n",
    "        else:\n",
    "            num_of_sample_per_segment = (2 / low_limitation) * sampling_rate\n",
    "        freqs, psd = welch(data, sampling_rate, nperseg=num_of_sample_per_segment)\n",
    "    elif method == 'multitaper':\n",
    "        psd, freqs = psd_array_multitaper(data, sampling_rate, adaptive=True,\n",
    "                                          normalization='full', verbose=0)\n",
    "    # Frequency resolution\n",
    "    freq_res = freqs[1] - freqs[0]\n",
    "\n",
    "    # Find index of band in frequency vector\n",
    "    idx_band1 = np.logical_and(freqs >= low_limitation1, freqs <= high_limitation1)\n",
    "    idx_band2 = np.logical_and(freqs >= low_limitation2, freqs <= high_limitation2)\n",
    "    idx_band3 = np.logical_and(freqs >= low_limitation3, freqs <= high_limitation3)\n",
    "    idx_band4 = np.logical_and(freqs >= low_limitation4, freqs <= high_limitation4)\n",
    "    idx_band5 = np.logical_and(freqs >= low_limitation5, freqs <= high_limitation5)\n",
    "    idx_band6 = np.logical_and(freqs >= low_limitation6, freqs <= high_limitation6)\n",
    "    idx_band7 = np.logical_and(freqs >= low_limitation7, freqs <= high_limitation7)\n",
    "    idx_band8 = np.logical_and(freqs >= low_limitation8, freqs <= high_limitation8)\n",
    "    idx_band9 = np.logical_and(freqs >= low_limitation9, freqs <= high_limitation9)\n",
    "    idx_band10 = np.logical_and(freqs >= low_limitation10, freqs <= high_limitation10)\n",
    "\n",
    "    # Integral approximation of the spectrum using parabola (Simpson's rule)\n",
    "    bp1 = simps(psd[idx_band1], dx=freq_res)\n",
    "    bp2 = simps(psd[idx_band2], dx=freq_res)\n",
    "    bp3 = simps(psd[idx_band3], dx=freq_res)\n",
    "    bp4 = simps(psd[idx_band4], dx=freq_res)\n",
    "    bp5 = simps(psd[idx_band5], dx=freq_res)\n",
    "    bp6 = simps(psd[idx_band6], dx=freq_res)\n",
    "    bp7 = simps(psd[idx_band7], dx=freq_res)\n",
    "    bp8 = simps(psd[idx_band8], dx=freq_res)\n",
    "    bp9 = simps(psd[idx_band9], dx=freq_res)\n",
    "    bp10 = simps(psd[idx_band10], dx=freq_res)\n",
    "    bp_general=simps(psd, dx=freq_res)\n",
    "    \n",
    "    bp_r1=bp1/bp_general\n",
    "    bp_r2=bp2/bp_general\n",
    "    bp_r3=bp3/bp_general\n",
    "    bp_r4=bp4/bp_general\n",
    "    bp_r5=bp5/bp_general\n",
    "    bp_r6=bp6/bp_general\n",
    "    bp_r7=bp7/bp_general\n",
    "    bp_r8=bp8/bp_general\n",
    "    bp_r9=bp9/bp_general\n",
    "    bp_r10=bp10/bp_general\n",
    "    bp=[bp1,bp2,bp3,bp4,bp5,bp6,bp7,bp8,bp9,bp10,bp_r1,bp_r2,bp_r3,bp_r4,bp_r5,bp_r6,bp_r7,bp_r8,bp_r9,bp_r10]       \n",
    "    return bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12a690b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcRms(x, scale):\n",
    "    \"\"\"\n",
    "    windowed Root Mean Square (RMS) with linear detrending.\n",
    "    \n",
    "    Args:\n",
    "    -----\n",
    "      *x* : numpy.array\n",
    "        one dimensional data vector\n",
    "      *scale* : int\n",
    "        length of the window in which RMS will be calculaed\n",
    "    Returns:\n",
    "    --------\n",
    "      *rms* : numpy.array\n",
    "        RMS data in each window with length len(x)//scale\n",
    "    \"\"\"\n",
    "    # making an array with data divided in windows\n",
    "    shape = (x.shape[0]//scale, scale)\n",
    "    X = np.lib.stride_tricks.as_strided(x,shape=shape)\n",
    "    # vector of x-axis points to regression\n",
    "    scale_ax = np.arange(scale)\n",
    "    rms = np.zeros(X.shape[0])\n",
    "    for e, xcut in enumerate(X):\n",
    "        coeff = np.polyfit(scale_ax, xcut, 1)\n",
    "        xfit = np.polyval(coeff, scale_ax)\n",
    "        # detrending and computing RMS of each window\n",
    "        rms[e] = np.sqrt(np.mean((xcut-xfit)**2))\n",
    "    return rms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae73c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfa(x, scale_lim=[5,9], scale_dens=0.32, show=False):\n",
    "    \"\"\"\n",
    "    Detrended Fluctuation Analysis - measures power law scaling coefficient\n",
    "    of the given signal *x*.\n",
    "    More details about the algorithm you can find e.g. here:\n",
    "    Hardstone, R. et al. Detrended fluctuation analysis: A scale-free \n",
    "    view on neuronal oscillations, (2012).\n",
    "    Args:\n",
    "    -----\n",
    "      *x* : numpy.array\n",
    "        one dimensional data vector\n",
    "      *scale_lim* = [5,9] : list of length 2 \n",
    "        boundaries of the scale, where scale means windows among which RMS\n",
    "        is calculated. Numbers from list are exponents of 2 to the power\n",
    "        of X, eg. [5,9] is in fact [2**5, 2**9].\n",
    "        You can think of it that if your signal is sampled with F_s = 128 Hz,\n",
    "        then the lowest considered scale would be 2**5/128 = 32/128 = 0.25,\n",
    "        so 250 ms.\n",
    "        mine: fs=1000, 2**5/1000=32/1000=0.032\n",
    "      *scale_dens* = 0.25 : float\n",
    "        density of scale divisions, eg. for 0.25 we get 2**[5, 5.25, 5.5, ... ] \n",
    "      *show* = False\n",
    "        if True it shows matplotlib log-log plot.\n",
    "    Returns:\n",
    "    --------\n",
    "      *scales* : numpy.array\n",
    "        vector of scales (x axis)\n",
    "      *fluct* : numpy.array\n",
    "        fluctuation function values (y axis)\n",
    "      *alpha* : float\n",
    "        estimation of DFA exponent\n",
    "    \"\"\"\n",
    "    # cumulative sum of data with substracted offset\n",
    "    y = np.cumsum(x - np.mean(x))\n",
    "    scales = (2**np.arange(scale_lim[0], scale_lim[1], scale_dens)).astype(np.int)\n",
    "    fluct = np.zeros(len(scales))\n",
    "    # computing RMS for each window\n",
    "    for e, sc in enumerate(scales):\n",
    "        fluct[e] = np.sqrt(np.mean(calcRms(y, sc)**2))\n",
    "    # fitting a line to rms data\n",
    "    coeff = np.polyfit(np.log2(scales), np.log2(fluct), 1)\n",
    "    if show:\n",
    "        fluctfit = 2**np.polyval(coeff,np.log2(scales))\n",
    "        plt.loglog(scales, fluct, 'bo')\n",
    "        plt.loglog(scales, fluctfit, 'r', label=r'$\\alpha$ = %0.2f'%coeff[0])\n",
    "        plt.title('DFA')\n",
    "        plt.xlabel(r'$\\log_{10}$(time window)')\n",
    "        plt.ylabel(r'$\\log_{10}$<F(t)>')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    return scales, fluct, coeff[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c16fb5c",
   "metadata": {},
   "source": [
    "# load and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9597703e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\mne\\externals\\pymatreader\\utils.py:118: UserWarning: Complex objects (like classes) are not supported. They are imported on a best effort base but your mileage will vary.\n",
      "  warn('Complex objects (like classes) are not supported. '\n",
      "<ipython-input-12-8b2d80a5f0ab>:1: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
      "  raw= mne.io.read_raw_eeglab('D:\\WM_openneuro_dataset\\sub-064\\eeg\\sub-064_task-rest_eeg.set')\n",
      "<ipython-input-12-8b2d80a5f0ab>:1: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw= mne.io.read_raw_eeglab('D:\\WM_openneuro_dataset\\sub-064\\eeg\\sub-064_task-rest_eeg.set')\n",
      "<ipython-input-12-8b2d80a5f0ab>:1: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw= mne.io.read_raw_eeglab('D:\\WM_openneuro_dataset\\sub-064\\eeg\\sub-064_task-rest_eeg.set')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['boundary', 'eyes opened']\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "2 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 2 events and 240001 original time points ...\n",
      "1 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "raw= mne.io.read_raw_eeglab('D:\\WM_openneuro_dataset\\sub-064\\eeg\\sub-064_task-rest_eeg.set')\n",
    "all_events, all_event_id = mne.events_from_annotations(raw)\n",
    "my_events= mne.pick_events(all_events)\n",
    "epochs = mne.Epochs(raw,my_events, tmin=0.0, tmax=240.0, baseline=(0, 0))\n",
    "data=epochs.to_data_frame()\n",
    "data.drop('time', axis=1, inplace=True)\n",
    "data.drop('condition', axis=1, inplace=True)\n",
    "data.drop('epoch', axis=1, inplace=True)\n",
    "data.drop([0],axis=0,inplace=True)\n",
    "edata=data.to_numpy(dtype ='float32')\n",
    "clm,rw =data.shape\n",
    "eeg=np.reshape(edata,(rw,-1))\n",
    "\n",
    "filter_signal = butterBandpass(eeg, 1, 45, 1000)\n",
    "filter_asr_signal = applyArtifactSubspaceReconstruction(filter_signal)\n",
    "np.save('s64_clean_resting_state', filter_asr_signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233966a5",
   "metadata": {},
   "source": [
    "# absolout and relative band power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6473f68a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filter_asr_signal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-a929994db744>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdelta_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdelta_p_rel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheta_p\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtheta_p_rel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha_p\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha_p_rel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbeta_p\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbeta_p_rel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgamma_p\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mgamma_p_rel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m21\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     band_power_all_band[ii] = bandpower(filter_asr_signal[ii,:], sampling_rate, [1, 4],[4, 8],\n\u001b[0m\u001b[0;32m      4\u001b[0m                                         \u001b[1;33m[\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m12\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m40\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m48\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m12\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                         [15, 18], [18, 25], [30, 35], [35, 40],'multitaper')\n",
      "\u001b[1;31mNameError\u001b[0m: name 'filter_asr_signal' is not defined"
     ]
    }
   ],
   "source": [
    "delta_p = delta_p_rel = theta_p=theta_p_rel=alpha_p=alpha_p_rel=beta_p=beta_p_rel=gamma_p= gamma_p_rel=np.zeros(21)\n",
    "for ii in range (0,20):\n",
    "    band_power_all_band[ii] = bandpower(filter_asr_signal[ii,:], sampling_rate, [1, 4],[4, 8],\n",
    "                                        [8, 12],[12, 25], [25, 30],[30, 40],[40, 48],[8, 10],[10, 12],[12, 15],\n",
    "                                        [15, 18], [18, 25], [30, 35], [35, 40],'multitaper')\n",
    "    #delta,  theta, alpha,  beta,    h_beta,  gamma,   h_gamma, alpha_1,alpha_2, beta_1,  beta_2, beta_3,  gama_1,  gama_2\n",
    "    #[1, 4],[4, 8],[8, 12],[12, 25],[25, 30],[30, 40],[40, 48],[8, 10],[10, 12],[12, 15],[15, 18],[18, 25],[30, 35],[35, 40]\n",
    "    np.save('s64_band_power_all_band', band_power_all_band)\n",
    "#ratio-power\n",
    "#db = bandpower(filter_asr_signal[1,:], sampling_rate, [0.5, 4], 'multitaper') / bandpower(filter_asr_signal[1,:], sampling_rate, [12, 30], 'multitaper')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae7fd94",
   "metadata": {},
   "source": [
    "# amplitude asymmetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea9098f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Amp_assym_delta=np.zeros((21,21))\n",
    "Amp_assym_theta=np.zeros((21,21))\n",
    "Amp_assym_alpha=np.zeros((21,21))\n",
    "Amp_assym_beta=np.zeros((21,21))\n",
    "Amp_assym_h_beta=np.zeros((21,21))\n",
    "Amp_assym_beta1=np.zeros((21,21))\n",
    "Amp_assym_beta2=np.zeros((21,21))\n",
    "Amp_assym_beta3=np.zeros((21,21))\n",
    "\n",
    "filter_signal_delta = butterBandpass(filter_asr_signal, 1, 4, 1000)\n",
    "filter_signal_theta = butterBandpass(filter_asr_signal, 4, 8, 1000)\n",
    "filter_signal_alpha = butterBandpass(filter_asr_signal, 8, 12, 1000)\n",
    "filter_signal_beta = butterBandpass(filter_asr_signal, 12, 25, 1000)\n",
    "filter_signal_h_beta = butterBandpass(filter_asr_signal, 25, 30, 1000)\n",
    "filter_signal_beta1 = butterBandpass(filter_asr_signal, 12, 15, 1000)\n",
    "filter_signal_beta2 = butterBandpass(filter_asr_signal, 15, 18, 1000)\n",
    "filter_signal_beta3 = butterBandpass(filter_asr_signal, 18, 25, 1000)\n",
    "for jj in range (0,20):\n",
    "    for j in range (0,20):\n",
    "        ch1_delta=filter_signal_delta[jj,:]\n",
    "        ch2_delta=filter_signal_delta[j,:] \n",
    "        p_delta_1=np.log(np.mean(np.abs(ch1_delta**2)))\n",
    "        p_delta_2=np.log(np.mean(np.abs(ch2_delta**2)))\n",
    "        Amp_assym_delta[jj,j]=p_delta_1-p_delta_2\n",
    "        \n",
    "        ch1_theta=filter_signal_theta[jj,:]\n",
    "        ch2_theta=filter_signal_theta[j,:] \n",
    "        p_theta_1=np.log(np.mean(np.abs(ch1_theta**2)))\n",
    "        p_theta_2=np.log(np.mean(np.abs(ch2_theta**2)))\n",
    "        Amp_assym_theta[jj,j]=p_theta_1-p_theta_2\n",
    "        \n",
    "        ch1_alpha=filter_signal_alpha[jj,:]\n",
    "        ch2_alpha=filter_signal_alpha[j,:] \n",
    "        p_alpha_1=np.log(np.mean(np.abs(ch1_alpha**2)))\n",
    "        p_alpha_2=np.log(np.mean(np.abs(ch2_alpha**2)))\n",
    "        Amp_assym_alpha[jj,j]=p_alpha_1-p_alpha_2\n",
    "        \n",
    "        ch1_beta=filter_signal_beta[jj,:]\n",
    "        ch2_beta=filter_signal_beta[j,:] \n",
    "        p_beta_1=np.log(np.mean(np.abs(ch1_beta**2)))\n",
    "        p_beta_2=np.log(np.mean(np.abs(ch2_beta**2)))\n",
    "        Amp_assym_beta[jj,j]=p_beta_1-p_beta_2\n",
    "        \n",
    "        ch1_h_beta=filter_signal_h_beta[jj,:]\n",
    "        ch2_h_beta=filter_signal_h_beta[j,:] \n",
    "        p_h_beta_1=np.log(np.mean(np.abs(ch1_h_beta**2)))\n",
    "        p_h_beta_2=np.log(np.mean(np.abs(ch2_h_beta**2)))\n",
    "        Amp_assym_h_beta[jj,j]=p_h_beta_1-p_h_beta_2\n",
    "        \n",
    "        ch1_beta_1=filter_signal_beta1[jj,:]\n",
    "        ch2_beta_1=filter_signal_beta1[j,:] \n",
    "        p_beta_1_1=np.log(np.mean(np.abs(ch1_beta_1**2)))\n",
    "        p_beta_1_2=np.log(np.mean(np.abs(ch2_beta_1**2)))\n",
    "        Amp_assym_beta1[jj,j]=p_beta_1_1-p_beta_1_2\n",
    "        \n",
    "        ch1_beta_2=filter_signal_beta2[jj,:]\n",
    "        ch2_beta_2=filter_signal_beta2[j,:] \n",
    "        p_beta_2_1=np.log(np.mean(np.abs(ch1_beta_2**2)))\n",
    "        p_beta_2_2=np.log(np.mean(np.abs(ch2_beta_2**2)))\n",
    "        Amp_assym_beta2[jj,j]=p_beta_2_1-p_beta_2_2\n",
    "        \n",
    "        ch1_beta_3=filter_signal_beta3[jj,:]\n",
    "        ch2_beta_3=filter_signal_beta3[j,:] \n",
    "        p_beta_3_1=np.log(np.mean(np.abs(ch1_beta_3**2)))\n",
    "        p_beta_3_2=np.log(np.mean(np.abs(ch2_beta_3**2)))\n",
    "        Amp_assym_beta3[jj,j]=p_beta_3_1-p_beta_3_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625b48de",
   "metadata": {},
   "source": [
    "# coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "785f59b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence1=np.zeros((21,21))\n",
    "c_delta=np.zeros((4,21,21))\n",
    "c_theta=np.zeros((4,21,21))\n",
    "c_alpha=np.zeros((5,21,21))\n",
    "c_beta=np.zeros((17,21,21))\n",
    "c_gamma=np.zeros((15,21,21))\n",
    "for jj in range (0,20):\n",
    "    for j in range (0,20):\n",
    "        ch_m=filter_asr_signal[jj,:]\n",
    "        ch_n=filter_asr_signal[j,:]\n",
    "        power_f=np.log(np.mean(np.abs(ch_m**2)))\n",
    "        power_ff=np.log(np.mean(np.abs(ch_n**2)))\n",
    "        fxx,cxx=ss.coherence(ch_m, ch_n, sampling_rate=1000, window='hann', nperseg=1000, noverlap=None, nfft=None, detrend='constant', axis=-1)\n",
    "        c_delta[:,jj,j]=cxx[1:5]\n",
    "        c_theta[:,jj,j]=cxx[5:9]\n",
    "        c_alpha[:,jj,j]=cxx[9:13]\n",
    "        c_beta[:,jj,j]=cxx[13:26]\n",
    "        c_h_beta[:,jj,j]=cxx[26:31]\n",
    "        c_beta1[:,jj,j]=cxx[13:16]\n",
    "        c_beta2[:,jj,j]=cxx[16:19]\n",
    "        c_beta3[:,jj,j]=cxx[19:26]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec2b580",
   "metadata": {},
   "source": [
    "# phase lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "986151e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a1cfe0348780>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mphase_diff\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m21\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m21\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mjj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mch1_delta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilter_signal_delta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mjj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mch2_delta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilter_signal_delta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "phase_diff=np.zeros((21,21))\n",
    "for jj in range (0,20):\n",
    "    for j in range (0,20):\n",
    "        ch1_delta=filter_signal_delta[jj,:]\n",
    "        ch2_delta=filter_signal_delta[j,:] \n",
    "        x1_delta= hilbert(ch1_delta)\n",
    "        x2_delta = hilbert(ch2_delta)\n",
    "        c_delta = np.inner( x1_delta, np.conj(x2_delta) )/np.sqrt( np.inner(x1_delta,np.conj(x1_delta)) * np.inner(x2_delta,np.conj(x2_delta)))\n",
    "        phase_diff_delta[jj,j]= np.angle(c_delata)\n",
    "       \n",
    "        ch1_theta=filter_signal_theta[jj,:]\n",
    "        ch2_theta=filter_signal_theta[j,:] \n",
    "        x1_theta= hilbert(ch1_theta)\n",
    "        x2_theta = hilbert(ch2_theta)\n",
    "        c_theta = np.inner( x1_theta, np.conj(x2_theta) )/np.sqrt( np.inner(x1_theta,np.conj(x1_theta)) * np.inner(x2_theta,np.conj(x2_theta)))\n",
    "        phase_diff_theta[jj,j]= np.angle(c_theta)\n",
    "       \n",
    "        ch1_alpha=filter_signal_alpha[jj,:]\n",
    "        ch2_alpha=filter_signal_alpha[j,:] \n",
    "        x1_alpha= hilbert(ch1_alpha)\n",
    "        x2_alpha = hilbert(ch2_alpha)\n",
    "        c_alpha = np.inner( x1_alpha, np.conj(x2_alpha) )/np.sqrt( np.inner(x1_alpha,np.conj(x1_alpha)) * np.inner(x2_alpha,np.conj(x2_alpha)))\n",
    "        phase_diff_alpha[jj,j]= np.angle(c_alpha)\n",
    "        \n",
    "        ch1_beta=filter_signal_beta[jj,:]\n",
    "        ch2_beta=filter_signal_beta[j,:] \n",
    "        x1_beta= hilbert(ch1_beta)\n",
    "        x2_beta = hilbert(ch2_beta)\n",
    "        c_beta= np.inner( x1_beta, np.conj(x2_beta) )/np.sqrt( np.inner(x1_beta,np.conj(x1_beta)) * np.inner(x2_beta,np.conj(x2_beta)))\n",
    "        phase_diff_beta[jj,j]= np.angle(c_beta)\n",
    "       \n",
    "       \n",
    "        ch1_h_beta=filter_signal_h_beta[jj,:]\n",
    "        ch2_h_beta=filter_signal_h_beta[j,:] \n",
    "        x1_h_beta= hilbert(ch1_h_beta)\n",
    "        x2_h_beta = hilbert(ch2_h_beta)\n",
    "        c_h_beta = np.inner( x1_h_beta, np.conj(x2_h_beta) )/np.sqrt( np.inner(x1_h_beta,np.conj(x1_h_beta)) * np.inner(x2_h_beta,np.conj(x2_h_beta)))\n",
    "        phase_diff_h_beta[jj,j]= np.angle(c_h_beta)\n",
    "        \n",
    "        ch1_beta1=filter_signal_beta1[jj,:]\n",
    "        ch2_beta1=filter_signal_beta1[j,:] \n",
    "        x1_beta1= hilbert(ch1_beta1)\n",
    "        x2_beta1 = hilbert(ch2_beta1)\n",
    "        c_beta1= np.inner( x1_beta1, np.conj(x2_beta1) )/np.sqrt( np.inner(x1_beta1,np.conj(x1_beta1)) * np.inner(x2_beta1,np.conj(x2_beta1)))\n",
    "        phase_diff_beta1[jj,j]= np.angle(c_beta1)\n",
    "        \n",
    "        ch1_beta2=filter_signal_beta2[jj,:]\n",
    "        ch2_beta2=filter_signal_beta2[j,:] \n",
    "        x1_beta2= hilbert(ch1_beta2)\n",
    "        x2_beta2 = hilbert(ch2_beta2)\n",
    "        c_beta2 = np.inner( x1_beta2, np.conj(x2_beta2) )/np.sqrt( np.inner(x1_beta2,np.conj(x1_beta2)) * np.inner(x2_beta2,np.conj(x2_beta2)))\n",
    "        phase_diff_beta2[jj,j]= np.angle(c_beta2)\n",
    "       \n",
    "        ch1_beta3=filter_signal_beta3[jj,:]\n",
    "        ch2_beta3=filter_signal_beta3[j,:] \n",
    "        x1_beta3= hilbert(ch1_beta3)\n",
    "        x2_beta3 = hilbert(ch2_beta3)\n",
    "        c_beta3 = np.inner( x1_beta3, np.conj(x2_beta3) )/np.sqrt( np.inner(x1_beta3,np.conj(x1_beta3)) * np.inner(x2_beta3,np.conj(x2_beta3)))\n",
    "        phase_diff_beta3[jj,j]= np.angle(c_beta3)\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ae608a",
   "metadata": {},
   "source": [
    "# DFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de36e2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfas=np.empty(21)\n",
    "for i in range (21):\n",
    "    if __name__=='__main__':\n",
    "        x_delta = np.abs(ss.hilbert(filter_signal_delta[i]))\n",
    "        scales, fluct, alpha_factor_delta = dfa(x_delta, show=1)\n",
    "        dfas_delta[i]=alpha_factor_delta\n",
    "        \n",
    "         x_theta = np.abs(ss.hilbert(filter_signal_theta[i]))\n",
    "        scales, fluct, alpha_factor_theta= dfa(x_theta, show=1)\n",
    "        dfas_theta[i]=alpha_factor_theta\n",
    "        \n",
    "         x_alpha= np.abs(ss.hilbert(filter_signal_alpha[i]))\n",
    "        scales, fluct, alpha_factor_alpha = dfa(x_alpha, show=1)\n",
    "        dfas_alpha[i]=alpha_factor_alpha\n",
    "        \n",
    "         x_beta = np.abs(ss.hilbert(filter_signal_beta[i]))\n",
    "        scales, fluct, alpha_factor_beta = dfa(x_beta, show=1)\n",
    "        dfas_beta[i]=alpha_factor_beta\n",
    "        \n",
    "         x_h_beta = np.abs(ss.hilbert(filter_signal_h_beta[i]))\n",
    "        scales, fluct, alpha_factor_h_beta = dfa(x_h_beta, show=1)\n",
    "        dfas_h_beta[i]=alpha_factor_h_beta\n",
    "        \n",
    "         x_beta1 = np.abs(ss.hilbert(filter_signal_beta1[i]))\n",
    "        scales, fluct, alpha_factor_beta1 = dfa(x_beta1, show=1)\n",
    "        dfas_beta1[i]=alpha_factor_beta1\n",
    "        \n",
    "         x_beta2 = np.abs(ss.hilbert(filter_signal_beta2[i]))\n",
    "        scales, fluct, alpha_factor_beta2 = dfa(x_beta2, show=1)\n",
    "        dfas_beta2[i]=alpha_factor_bet2\n",
    "        \n",
    "         x_beta3 = np.abs(ss.hilbert(filter_signal_beta3[i]))\n",
    "        scales, fluct, alpha_factor_beta3 = dfa(x_beta3, show=1)\n",
    "        dfas_beta3[i]=alpha_factor_beta3\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
